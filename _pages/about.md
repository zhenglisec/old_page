---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html

---

I am currently a postdoc at [CISPA Helmholtz Center for Information Security](https://cispa.de/), supervised by [Dr. Yang Zhang](https://yangzhangalmo.github.io/). Prior to that, I obtained my Ph.D. (2023) degree from [CISPA Helmholtz Center for Information Security](https://cispa.de/) under the supervision of [Dr. Yang Zhang](https://yangzhangalmo.github.io/). I received my bachelor (2017) and master (2020) degrees from [Shandong University](https://www.sdu.edu.cn/) under the supervision of [Prof. Shanqing Guo](https://faculty.sdu.edu.cn/guoshanqing/zh_CN/index.htm).

## Research Interests

My research centers on Trustworthy Machine Learning (Privacy, Security, and Safety), especially analyzing machine learning model vulnerabilities, including privacy attacks (MIA and AIA), backdoors, and data poison attacks. Additionally, I work on technical solutions against unethical AI systems.

## Experiences & Education 

- [2023.11 – current] PostDoc at CISPA Helmholtz Center for Information Security. Supervised by Dr. Yang Zhang.
- [2022.07 – 2022.10] Research Intern at Bell Lab. hosted by Ruichuan Chen.
- [2021.02 – 2023.10] Ph.D. in Computer Science, CISPA Helmholtz Center for Information Security. Supervised by Dr. Yang Zhang.
- [2017.09 – 2020.06] Master in Computer Science, Shandong University. Supervised by Prof. Shanqing Guo.
- [2013.09 – 2017.06] Bachelor in Computer Science, Shandong University. Supervised by Prof. Shanqing Guo.

## News
- [12/2023] One paper titled “Detection and Attribution of Models Trained on Generated Data” got accepted in ICASSP 2024!
- [10/2023] I have successfully passed my Ph.D. defense!
- [09/2023] One paper titled “SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models” got accepted in USENIX Security 2024!
- [05/2023] One paper titled “DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Generation Models” got accepted in CCS 2023!
- [05/2023] One paper titled “NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models” got accepted in ACL 2023!
- [04/2023] One paper titled “Data Poisoning Attacks Against Multimodal Encoders” got accepted in ICML 2023!
- [12/2022] One paper titled "Backdoor Attacks Against Dataset Distillation" got accepted in NDSS 2023!
- [9/2022] One paper titled "UnGANable: Defending Against GAN-based Face Manipulation" got accepted in USENIX Security 2023!
- [7/2022] I started an internship at Bell Lab!
- [4/2022] One paper titled "Auditing Membership Leakages of Multi-Exit Networks" got accepted in CCS 2022!
- [3/2021] One paper titled "Membership Leakage in Label-Only Exposures" got accepted in CCS 2021!
- [8/2019] One paper titled "How to Prove Your Model Belongs to You: A Blind-Watermark based Framework to Protect Intellectual Property of DNN" got accepted in ACSAC 2019!
- [5/2019] One paper titled "DeepKeyStego: Protecting Communication by Key-dependent Steganography with Deep Networks" got accepted in HPCC 2019!

