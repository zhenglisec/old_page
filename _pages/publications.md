---
title: ""
permalink: /publications/
author_profile: true
---

<style type="text/css" rel="stylesheet">
.btn--paper {
color: white;
background-color: lightseagreen;
padding: 1px 3px;
text-align: center;
border-radius: 4px;
a { TEXT-DECORATION:none }
}
.btn--arxiv {
color: white;
background-color: tan;
padding: 1px 3px;
text-align: center;
border-radius: 4px;
a { TEXT-DECORATION:none }
}
.btn--code {
color: white;
background-color: DARKORANGE;
padding: 1px 3px;
text-align: center;
border-radius: 4px;
a { TEXT-DECORATION:none }
}
</style>

<h2 id='2024'>2024</h2>

### <span style="color:rgb(39, 117, 182)">SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models</span>
<font size="3"> Boyang Zhang, <b>Zheng Li</b>, Ziqing Yang, Xinlei He, Michael Backes, Mario Fritz, Yang Zhang;
<i>USENIX Security 2024</i></font>
<a href="https://zhenglisec.github.io/" class="btn--paper" target="_blank">pdf</a>
<a href="https://zhenglisec.github.io/" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://zhenglisec.github.io/" class="btn--code" target="_blank">code</a>

<h2 id='2023'>2023</h2>

### <span style="color:rgb(39, 117, 182)">UnGANable: Defending Against GAN-based Face Manipulation</span>
<font size="3"> <b>Zheng Li</b>, Ning Yu, Ahmed Salem, Michael Backes, Mario Fritz, Yang Zhang;
<i>USENIX Security 2023</i></font>
<a href="https://arxiv.org/abs/2210.00957" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2210.00957" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/zhenglisec/UnGANable" class="btn--code" target="_blank">code</a>

### <span style="color:rgb(39, 117, 182)">DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Generation Models</span>
<font size="3">Zeyang Sha, <b>Zheng Li</b>, Ning Yu, Yang Zhang;
<i>CCS 2023</i></font>
<a href="https://arxiv.org/abs/2210.06998" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2210.06998" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://arxiv.org/abs/2210.06998" class="btn--code" target="_blank">code</a>

### <span style="color:rgb(39, 117, 182)">Data Poisoning Attacks Against Multimodal Encoders</span>
<font size="3">Ziqing Yang, Xinlei He, <b>Zheng Li</b>, Michael Backes, Mathias Humbert, Pascal Berrang, Yang Zhang;
<i>ICML 2023</i></font>
<a href="https://arxiv.org/abs/2209.15266" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2209.15266" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/zqypku/mm_poison/" class="btn--code" target="_blank">code</a>

### <span style="color:rgb(39, 117, 182)">NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models</span>
<font size="3">Kai Mei, <b>Zheng Li</b>, Zhenting Wang, Yang Zhang, Shiqing Ma;
<i>ACL 2023</i></font>
<a href="https://zhenglisec.github.io/" class="btn--paper" target="_blank">pdf</a>
<a href="https://zhenglisec.github.io/" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://zhenglisec.github.io/" class="btn--code" target="_blank">code</a>

### <span style="color:rgb(39, 117, 182)">Backdoor Attacks Against Dataset Distillation</span>
<font size="3">Yugeng Liu, <b>Zheng Li</b>, Michael Backes, Yun Shen, Yang Zhang;
<i>NDSS 2023</i></font>
<a href="https://arxiv.org/abs/2301.01197" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2301.01197" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/liuyugeng/baadd" class="btn--code" target="_blank">code</a>

### <span style="color:rgb(39, 117, 182)">Watermarking Diffusion Model</span>
<font size="3">Yugeng Liu, <b>Zheng Li</b>, Michael Backes, Yun Shen, Yang Zhang;</font>
<a href="https://arxiv.org/abs/2305.12502" class="btn--arxiv" target="_blank">arxiv</a>

### <span style="color:rgb(39, 117, 182)">Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis</span>
<font size="3">Yihan Ma, Zhengyu Zhao, Xinlei He, <b>Zheng Li</b>, Michael Backes, Yang Zhang;</font>
<a href="https://arxiv.org/abs/2306.07754" class="btn--arxiv" target="_blank">arxiv</a>

<h2 id='2022'>2022</h2>

### <span style="color:rgb(39, 117, 182)">Auditing Membership Leakages of Multi-Exit Networks</span>
<font size="3"><b>Zheng Li</b>, Yiyong Liu, Xinlei He, Ning Yu, Michael Backes, Yang Zhang;
<i>CCS 2022</i></font>
<a href="https://arxiv.org/abs/2208.11180" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2208.11180" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/zhenglisec/Multi-Exit-Privacy" class="btn--code" target="_blank">code</a>


### <span style="color:rgb(39, 117, 182)">Membership-Doctor: Comprehensive Assessment of Membership Inference Against Machine Learning Models</span>
<font size="3">Xinlei He, <b>Zheng Li</b>, Weilin Xu, Cory Cornelius, Yang Zhang;</font>
<a href="https://arxiv.org/abs/2208.10445" class="btn--arxiv" target="_blank">arxiv</a>

### <span style="color:rgb(39, 117, 182)">Membership Inference Attacks Against Text-to-image Generation Models</span>
<font size="3">Yixin Wu, Ning Yu, <b>Zheng Li</b>, Michael Backes, Yang Zhang;</font>
<a href="https://arxiv.org/abs/2210.00968" class="btn--arxiv" target="_blank">arxiv</a>

### <span style="color:rgb(39, 117, 182)">Backdoor Attacks in the Supply Chain of Masked Image Modeling</span>
<font size="3">Xinyue Shen, Xinlei He, <b>Zheng Li</b>, Yun Shen, Michael Backes, Yang Zhang;</font>
<a href="https://arxiv.org/abs/2210.01632" class="btn--arxiv" target="_blank">arxiv</a>


<h2 id='2021'>2021</h2>

### <span style="color:rgb(39, 117, 182)">Membership Leakage in Label-Only Exposures</span>
<font size="3"><b>Zheng Li</b>, Yang Zhang;
<i>CCS 2021</i></font>
<a href="https://arxiv.org/abs/2007.15528" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2007.15528" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/zhenglisec/Decision-based-MIA" class="btn--code" target="_blank">code</a>


<h2 id='2019'>2019</h2>

### <span style="color:rgb(39, 117, 182)">How to Prove Your Model Belongs to You: A Blind-Watermark based Framework to Protect Intellectual Property of DNN</span>
<font size="3"><b>Zheng Li</b>,  Chengyu Hu, Yang Zhang, Shanqing Guo;
<i>ACSAC 2019</i></font>
<a href="https://arxiv.org/abs/1903.01743" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/1903.01743" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/zhenglisec/Blind-Watermark-for-DNN" class="btn--code" target="_blank">code</a>


### <span style="color:rgb(39, 117, 182)">DeepKeyStego: Protecting Communication by Key-dependent Steganography with Deep Networks</span>
<font size="3"><b>Zheng Li</b>,  Ge Han, Shanqing Guo, Chengyu Hu;
<i>HPCC 2019</i></font>
<a href="https://ieeexplore.ieee.org/document/8855704" class="btn--paper" target="_blank">pdf</a>
<a href="https://ieeexplore.ieee.org/document/8855704" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/zhenglisec/DeepKeyStego" class="btn--code" target="_blank">code</a>



